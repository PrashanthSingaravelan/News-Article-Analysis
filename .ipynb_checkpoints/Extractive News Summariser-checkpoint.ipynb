{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71594a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac84f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all sentences to lower cases\n",
    "def casefolding(sentence):\n",
    "    return sentence.lower()\n",
    "\n",
    "## Removes all punctuation and numbers, leaving only the alphabet characters\n",
    "def cleaning(sentence):\n",
    "    return re.sub(r'[^a-z]', ' ', re.sub(\"’\", '', sentence))\n",
    "\n",
    "def tokenization(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "def stopword_removal(self, token):\n",
    "    temp = []\n",
    "    for i in range(len(token)):\n",
    "        if token[i] not in self.stopwords:\n",
    "            temp.append(token[i])\n",
    "    return temp\n",
    "\n",
    "## Whole story into collection of sentences (Tokenisation)\n",
    "def sentence_split(paragraph):\n",
    "    return nltk.sent_tokenize(paragraph)\n",
    "\n",
    "## Giving weighs to the words to determine whether it has effect or not\n",
    "def word_freq(data):\n",
    "    w = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        for words in sentence:\n",
    "            w.append(words)\n",
    "    bag = list(set(w))\n",
    "    res = {}\n",
    "    \n",
    "    for word in bag:\n",
    "        res[word] = w.count(word)\n",
    "    return res\n",
    "\n",
    "## Knowing the weighs of each senteces (whether the sentence represents the best story)\n",
    "def sentence_weight(data):\n",
    "    weights = []\n",
    "    for words in data:\n",
    "        temp = 0\n",
    "        for word in words:\n",
    "            temp += wordfreq[word]\n",
    "        weights.append(temp)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe28a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = '''\n",
    "Citing that 10% commission cap is not financially sustainable, taxi aggregator Uber is contemplating to limit \n",
    "auto services in selected parts of Bengaluru where the service is viable. In a statement, Nitish Bhushan, \n",
    "head of Central Operations of Uber in India and South Asia, said: “If our costs cannot be covered through commissions, we will have to find ways to offload costs that could impact the experience of drivers and riders. In the face of these commission caps, we may have to make the difficult decision to limit Uber Auto to select parts of Bengaluru where the service is viable. This will hurt drivers and inconvenience riders who depend on aggregators for their commuting needs.”It can be recalled that the State government recently banned the operations of auto services by the mobile app based aggregators after receiving complaints about fleecing passengers by charging exorbitant fares. The order was challenged by the aggregators in the Karnataka High Court. Later, the aggregators \n",
    "were allowed to charge 10% on the fare collected (as per the fares fixed by the Transport Department) as commission.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a71bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting based upon full stops\n",
    "sentence_list = sentence_split(news)\n",
    "sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sentence in sentence_list:\n",
    "    data.append(tokenization(cleaning(casefolding(sentence))))\n",
    "data = (list(filter(None, data)))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb06d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = word_freq(data)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a41a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = sentence_weight(data)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7146c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "result = ''\n",
    "sort_list = np.argsort(rank)[::-1][:n]\n",
    "for i in range(n):\n",
    "    result += '{} '.format(sentence_list[sort_list[i]])\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
